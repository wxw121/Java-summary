####  MySQL日志系统之redo log、bin log和undo log

##### undo log

undo log 主要用于实现 MVCC，从而**实现 MySQL 的 ”读已提交“、”可重复读“ 隔离级别。在每个行记录后面有两个隐藏列，"trx_id"、"roll_pointer"，分别表示上一次修改的事务id，以及 "上一次修改之前保存在 undo log中的记录位置 "。**在对一行记录进行修改或删除操作前，会先将该记录拷贝一份到 undo log 中，然后再进行修改，并将修改事务 id，拷贝的记录在 undo log 中的位置写入 "trx_id"、"roll_pointer"。

MVCC 最核心的就是 **版本链** 和通过版本链生成的 **Read View**。

版本链：通过 "roll_pointer" 字段指向的上一次修改的值，使每行记录变化前后形成了一条版本链。

Read View：Read View 表示可见视图，用于限制当前事务查询数据的，通过与版本链的配合可以实现对数据的 “快照读” 。Read View 内部主要有四个部分组成，第一个是创建当前 Read View 的事务 id creator_trx_id，第二个是创建 Read View 时还未提交的事务 id 集合trx_ids，第三个是未提交事务 id 集合中的最大值up_limit_id，第四个是未提交事务 id 集合中的最小值low_limit_id。当执行查询操作时会先找磁盘上的数据，然后根据 Read View 里的各个值进行判断。

1. 如果该数据的 trx_id 等于 creator_trx_id，那么就说明这条数据是创建 Read View的事务修改的，那么就直接返回；
2. 如果 trx_id 大于等于 up_limit_id，说明是新事务修改的，那么会根据 roll_pointer 找到上一个版本的数据重新比较；
3. 如果 trx_id 小于 low_limit_id，那么说明是之前的事务修改的数据，那么就直接返回；
4. 如果 trx_id 是在 low_limit_id 与 up_limit_id 中间，那么需要去 trx_ids 中对各个元素逐个判断，如果存在相同值的元素，就根据 roll_pointer 找到上一个版本的数据，然后再重复判断；如果不存在就说明该数据是创建当前 Read View 时就已经修改好的了，可以返回。

**而读已提交和可重复读之所以不同就是它们 Read View 生成机制不同，读已提交是每次 select 都会重新生成一次，而可重复读是一次事务只会创建一次且在第一次查询时创建 Read View。事务启动命令begin/start transaction不会创建Read View，但是通过 start transaction with consistent snapshot 开启事务就会在开始时就创建一次 Read View。**

总结：undo log实现MySQL读已提交，可重复读的依据就是根据每行后面两个字段trx_id和roll_pointer的比对（比对的规则就是执行查询操作时会先找到磁盘上的数据，然后根据Read View里的各个值进行判断，从而获取上一次修改的事务id），因为读已提交和可重复读它们Read View生成机制不同（读已提交是每次select操作会生成一次，可重复读是一次事务只创建一次并且在第一次查询时创建Read View），所以查询的结果也就不同。

##### redo log（重做日志）

存储在数据库data目录下，格式为ib_logfile0。

**作用：降低随机写的性能消耗（转成顺序写），同时防止写操作因为宕机而丢失。** MySQL 中，如果每一次的更新操作都需要写进磁盘，然后磁盘也要找到对应的那条记录，然后再更新，整个过程 IO 成本、查找成本都很高。为了解决这个问题，MySQL 的设计者就采用了日志（redo log）来提升更新效率。而日志和磁盘配合的整个过程，其实就是 MySQL 里的 WAL 技术(先写日志，再写磁盘)。

具体来说，当有一条记录需要更新的时候，InnoDB 引擎就会先把记录写到 redo log（redolog buffer）里面，并更新内存（buffer pool），这个时候更新就算完成了。同时，InnoDB 引擎会在适当的时候（如系统空闲时），将这个操作记录更新到磁盘里面（刷脏页）。redo log 是 InnoDB 存储引擎层的日志，又称重做日志文件，redo log 是循环写的，redo log 不是记录数据页更新之后的状态，而是记录这个页做了什么改动。

**写操作写入redo log的三种状态（过程）：**

1. 写入 redo log buffer 中，这部分是属于MySQL 的内存中，是**全局公用**的。
2. 在事务编写完成后，就可以执行 write 操作，写到文件系统的 page cache 中，属于操作系统的内存，如果 MySQL 崩溃不会影响，但如果机器断电则会丢失数据。
3. 执行 fsync（持久化）操作，将 page cache 中的数据正式写入磁盘上的 redo log 中。

**redo log持久化**

![image-20210829214229736](C:\Users\wuxiaowen\AppData\Roaming\Typora\typora-user-images\image-20210829214229736.png)

##### bin log（归档日志）

存储在数据库data目录下，格式为xxx-bin.000001。

binlog 也是保存写操作的，但是它**主要是用于进行集群中保证主从一致以及执行异常操作后恢复数据的。**

**作用：写操作的备份，保证主从一致。** 属于逻辑日志，是以二进制的形式记录的是这个语句的原始逻辑，依靠 binlog 是没有 crash-safe 能力的。binlog 有两种模式，statement 格式的话是记 sql 语句**（不能完成主从复制的操作，比如在操作中加入了Now()函数，主从数据库操作的时间不同结果也不同）**（可以使用 "show binlog events in '文件名'" 来查看 statement 格式的日志内容，**一个事务的结尾会有 " COMMIT " 标志**），row 格式（5.7默认）会记录行的内容，记两条，更新前和更新后都有（内容可以通过 " MySQLbinlog + 文件名 " 来查看）。

**binlog持久化：**

- sync_binlog 这个参数设置成 1 的时候，表示每次事务的 binlog 都持久化到磁盘。这个参数也建议设置成 1，这样可以保证 MySQL 异常重启之后 binlog 不丢失。
- sync_binlog=0 的时候，表示每次提交事务都只 write，不 fsync；
- sync_binlog=N(N>1) 的时候，表示每次提交事务都 write，但累积 N 个事务后才 fsync

为什么会有两份日志呢？

**因为最开始 MySQL 里并没有 InnoDB 引擎。MySQL 自带的引擎是 MyISAM，但是 MyISAM 没有 crash-safe 的能力，binlog 日志只能用于归档。**而 InnoDB 是另一个公司以插件形式引入 MySQL 的，既然只依靠 binlog 是没有 crash-safe 能力的，所以 InnoDB 使用另外一套日志系统——也就是 redo log 来实现 crash-safe 能力。

**写操作三种状态：**

1. write：从binglog cache（**每个线程各有一份**）写到 page cache。
2. fsync：将数据持久化到磁盘。

##### 三种日志区别

1. redo log 和 undo log是 InnoDB 引擎特有的；binlog 是 MySQL 的 Server 层实现的，所有引擎都可以使用。
2. undo log 记录的是行记录变化前的数据；redo log （物理日志）记录的是 sql 的数据页修改逻辑以及 change buffer 的变更；bin log（逻辑日志）记录操作语句对具体行的操作以及操作前的整行信息（5.7默认）或者sql语句。
3. redo log 是循环写的，空间固定会用完；binlog 是可以追加写入的。追加写是指 binlog 文件写到一定大小后会切换到下一个，并不会覆盖以前的日志。
4. undo log是用于事务的回滚、保证事务隔离级别读已提交、可重复读实现的。redo log是用于对暂不更新到磁盘上的操作进行记录，使得其可以延迟落盘，保证程序的效率。bin log是对数据操作进行备份恢复（并不能依靠 bin log 直接完成数据恢复）。
5. 单独的 binlog 没有 crash-safe 能力，也就是在异常断电后，之前已经提交但未更新的事务操作到磁盘的操作会丢失，也就是主从复制的一致性无法保障，而 redo log 有 crash-safe 能力，通过与 redo log 的配合实现 "三步提交"，就可以让主从库的数据也能保证一致性。

##### 执行器和 InnoDB 引擎在执行这个 update 语句时的内部流程（UPDATE T SET c = c + 1 WHERE ID = 2;）

1. 执行器先找引擎取 ID=2 这一行。ID 是主键，引擎直接用树搜索找到这一行。如果 ID=2 这一行所在的数据页本来就在内存中，就直接返回给执行器；否则，需要先从磁盘读入内存，然后再返回。
2. 执行器拿到引擎给的行数据，把这个值加上 1，比如原来是 N，现在就是 N+1，得到新的一行数据，再调用引擎接口写入这行新数据。
3. 引擎将这行新数据更新到内存（InnoDB Buffer Pool）中，同时将这个更新操作记录到 redo log 里面，此时 redo log 处于 prepare 状态。然后告知执行器执行完成了，随时可以提交事务。
4. 执行器生成这个操作的 binlog，并把 binlog 写入磁盘。
5. 执行器调用引擎的提交事务接口，引擎把刚刚写入的 redo log 改成提交（commit）状态，更新完成。

##### 两阶段提交（2PC）

MySQL 使用两阶段提交主要解决 binlog 和 redo log 的数据一致性的问题。**redo log 和 binlog 都可以用于表示事务的提交状态，而两阶段提交就是让这两个状态保持逻辑上的一致。**

两阶段提交原理描述：

1. InnoDB redo log 写盘，InnoDB 事务进入 prepare 状态。
2. 如果前面 prepare 成功，binlog 写盘，那么再继续将事务日志持久化到 binlog，如果持久化成功，那么 InnoDB 事务则进入 commit 状态(在 redo log 里面写一个 commit 记录)

注意: 每个事务 binlog 的末尾，会记录一个 XID event，标志着事务是否提交成功，也就是说，recovery 过程中，binlog 最后一个 XID event 之后的内容都应该被 purge（清除）。

##### 怎么进行数据恢复？

binlog 会记录所有的逻辑操作，并且是采用追加写的形式。当需要恢复到指定的某一秒时，比如今天下午二点发现中午十二点有一次误删表，需要找回数据，那你可以这么做：

- 首先，找到最近的一次全量备份，从这个备份恢复到临时库
- 然后，从备份的时间点开始，将备份的 binlog 依次取出来，重放到中午误删表之前的那个时刻。

这样你的临时库就跟误删之前的线上库一样了，然后你可以把表数据从临时库取出来，按需要恢复到线上库去。

##### redo log 和 binlog 是怎么关联起来的?

redo log 和 binlog 有一个共同的数据字段，叫 XID。崩溃恢复的时候，会按顺序扫描 redo log：

- 如果碰到既有 prepare、又有 commit 的 redo log，就直接提交；
- 如果碰到只有 parepare、而没有 commit 的 redo log，就拿着 XID 去 binlog 找对应的事务。

##### MySQL 怎么知道 binlog 是完整的?

一个事务的 binlog 是有完整格式的：

- statement 格式的 binlog，最后会有 COMMIT
- row 格式的 binlog，最后会有一个 XID event

在 MySQL 5.6.2 版本以后，还引入了 binlog-checksum 参数，用来验证 binlog 内容的正确性。对于 binlog 日志由于磁盘原因，可能会在日志中间出错的情况，MySQL 可以通过校验 checksum 的结果来发现。所以，MySQL 是有办法验证事务 binlog 的完整性的。

##### redo log 一般设置多大？

redo log 太小的话，会导致很快就被写满，然后不得不强行刷 redo log，这样 WAL 机制的能力就发挥不出来了。

如果是几个 TB 的磁盘的话，直接将 redo log 设置为 4 个文件，每个文件 1GB。

##### 数据写入后的最终落盘，是从 redo log 更新过来的还是从 buffer pool（内存） 更新过来的呢？

实际上，redo log 并没有记录数据页的完整数据，所以它并没有能力自己去更新磁盘数据页，也就不存在由 redo log 更新过去数据最终落盘的情况。redo log 的作用就是持久化记录的写操作，防止在写操作更新到磁盘前发生断电丢失这些写操作，**直到该操作对应的脏页真正落盘（先读取数据页到缓冲池然后应用写操作到缓冲池，最后再将脏页落盘替换磁盘上的数据页），该操作才会从 redo log 中移除（覆盖）**。

1. 数据页被修改以后，跟磁盘的数据页不一致，称为脏页。最终数据落盘，就是把内存中的数据页写盘。这个过程与 redo log 毫无关系。
2. 在崩溃恢复场景中，InnoDB 如果判断到一个数据页可能在崩溃恢复的时候丢失了更新，就会将它读到内存，然后让 redo log 更新内存内容。更新完成后，内存页变成脏页，就回到了第一种情况的状态。

##### redo log buffer 是什么？是先修改内存，还是先写 redo log 文件？

```
在一个事务的更新过程中，日志是要写多次的。比如下面这个事务：
begin;
INSERT INTO T1 VALUES ('1', '1');
INSERT INTO T2 VALUES ('1', '1');
commit;
```

它就是一块内存，用来先存 redo 日志的。也就是说，在执行第一个 insert 的时候，数据的内存被修改了，redo log buffer 也写入了日志。但是，真正把日志写到 redo log 文件，是在执行 commit 语句的时候做的。

redo log buffer 本质上只是一个 byte 数组，但是为了维护这个 buffer 还需要设置很多其他的 meta data，这些 meta data 全部封装在 log_t 结构体中。

##### Crash-Safe能力

Crash-safe 能力，指的是在机器突然断电重启后，之前的数据不会丢失，能够恢复成断电前状态的能力。redo log 拥有 crash-safe 能力，而 binlog 没有。这是因为 **redo log 记录的是未更新到磁盘上的操作，在断电后只需要将记录的操作数据更新到缓冲池中就可以了。而 binlog 记录的是所有请求过来的写操作，这个写操作在断电前有没有落盘并不知道**。正因为如此所以采用 redo log 与 binlog 的 “ 三步提交 ” （两阶段提交）来保证 binlog 也具有 crash-safe 能力。

首先**在断电重启后先检查 redo log 记录的事务操作是否为 commit 状态**：

1. **如果是 commit 状态说明没有数据丢失，判断下一个。**
2. **如果是 prepare 状态，检查 binlog 记录的对应事务操作（redo log 与 binlog 记录的事务操作有一个共同字段 XID，redo log 就是通过这个字段找到 binlog 中对应的事务的）是否完整（这点在前面 binlog 三种格式分析过，每种格式记录的事务结尾都有特定的标识），如果完整就将 redo log 设为 commit 状态，然后结束；不完整就回滚 redo log 的事务，结束。**

**三步提交的前提：**

如果想要数据库拥有 " crash-safe " 能力，那么就需要将 redo log 的持久化策略参数 innodb_flush_log_at_trx_commit 设为1，binlog 的持久化策略参数 sync_binlog 设为大于0。（可能伴随着很大的性能消耗，某些场景不适用，**非双1场景一般设置：innodb_flush_logs_at_trx_commit=2、sync_binlog=1000。**）

**组提交优化 " 三步提交 "：**

优化前："双一配置"会给服务器系统带来很大的I/O压力。

优化方式：日志逻辑序列号（log sequence number，LSN）表示redo log记载的写入点，也就是最新写入事务的开始点，其前面都是已写完的事务。**因为 redo log 写入 “ redo log buffer 完成 “ 到 " write 到 page cache"、" 正式开始 fsync " 需要时间，在这个时间内可能伴随着多个事务的写入完成，那么就可以以第一个事务为准，在持久化时将操作记录完成的事务合并一起进行 fsync。**

**在并发更新的场景下，第一个事务写到 redo log buffer后，越晚 fsync，组内堆积的事务就越多，组提交提高的效率也就越高，所以在三步提交中 redo log 的 prepare 写是分为两部分，首先执行write 操作写到 page cache 后会先执行 binlog 的 write 操作，执行结束后再执行 redo log prepare 状态的 fsync 操作。这样就可以延长 fsync 的时间，提高组提交节省的资源。**因为 binlog 也拥有组提交，所以这样执行也可以提高 binlog 的 IO 消耗，但单条 redo log 的 fsync 执行的很快，为了进一步提高 binlog 组提交节省的资源，还可以通过参数 binlog_group_commit_sync_delay 和 binlog_group_commit_sync_no_delay_count 来延长 binlog 执行 fsync 的时间。 

**三步提交总结：**

- 在 redo log 持久化参数 innodb_flush_log_at_trx_commit 设为 1 时，每次提交、每秒钟都会清空 redo log buffer 来执行三步提交，而在两个日志 fsync 持久化时还会分组来进行组提交，减少磁盘IO 次数。
- 组提交是以组为单位按顺序进行写操作的，从 redo log prepare 状态开始到 redo log commit 状态同一时刻只会有一个组的事务在执行。
- 一个组的事务中的操作对某一行的操作一定是唯一的。因为如果两个事务对同一行记录进行操作，那么一定有一个事务会被行锁所阻塞，导致其不会跟另一个事务在同一个组内。

#### MySQL索引优化

##### 常用索引

聚集索引（主键索引）：

​      聚集索引就是按照每张表的主键构造一颗B+树，同时叶子节点中存放的即为整张表的记录数据。

​      聚集索引的叶子节点称为数据页，聚集索引的这个特性决定了索引组织表中的数据也是索引的一部分。

辅助索引（二级索引）：

​      非主键索引，叶子节点=键值+书签。Innodb存储引擎的书签就是相应行数据的主键索引值。

##### 什么情况需要索引

1. 主键自动建立唯一索引
2. 频繁作为查询条件的字段应该创建索引
3. 查询中与其他表关联的字段，外键关系建立索引
4. 频繁更新的字段不适合创建索引
5. where条件中用不到的字段不创建索引
6. 并发量较高时，推荐使用组合索引（单键索引和组合索引的选择）
7. 查询中排序的字段，排序字段若通过索引去访问将大大提高排序速度
8. 查询中统计或者分组字段

##### 哪些情况不要创建索引

1. 表记录太少
2. 经常增删改的表
3. 数据重复且分布平均的表字段，因此应该只为最经常查询和最经常排序的数据列建索引。注意，如果某个数据列包含许多重复的内容，为它建立索引就没有太大的实际效果。

##### MySQL常见瓶颈

CPU：CPU在饱和的时候一般发生在数据装入内存或从磁盘上读取数据的时候

IO：磁盘I/O瓶颈发生在装入数据远大于内存容量的时候

通过top,free,iostat,vmstat来查看系统的性能状态

##### Hash值创建索引的技巧

如果表中有一列存储较长字符串，假设名字为URL，在此列上创建的索引比较大，有个办法可以缓解：创建URL字符串的数字哈希值的索引。

再新建一个字段，比如叫做URL_CRC，专门放置URL的哈希值，然后给这个字段创建索引，查询时这样写：

> ```sql
> select * from t where URL_CRC = 387695885 and URL = 'www.baidu.com'
> ```

如果数据量比较多，为防止哈希冲突，可自定义哈希函数，或用MD5函数返回值的一部分作为哈希值：

> ```sql
> SELECT CONV(RIGHT(MD5('www.baidu.com'),16), 16, 10)
> ```

##### Explain

使用explain关键字可以模拟优化器执行Sql查询语句，从而知道MySQL如何处理你的Sql语句的，进而分析你的Sql语句和性能瓶颈。

explain + Sql

结果包含的信息：

- id：select查询的序列号，包含一组数字，表示查询中执行select子句或操作表的顺序。
  1. id相同时，执行顺序由上至下。
  2. id不同，如果是子查询，id的序号会递增，id越大优先级越高越先被执行。

- select_type：查询的类型，主要是区分普通查询、联合查询、子查询等的复杂查询。
  1. SIMPLE：简单select查询，不包含子查询和UNION。
  2. PRIMARY：查询中包含复杂的子查询，最外层查询被标记为PRIMARY。
  3. SUBQUERY：在select和where中包含了子查询。
  4. DERIVED（衍生）：在from列表中包含的子查询被标记为DERIVED。MySQL会递归执行这些子查询，把查询结果放在临时表中。
  5. UNION：若第二个select出现在UNION后，则该查询就被标记为UNION。若UNION出现在from查询的子查询中，外层的SELECT就被标记为DERIVED。
  6. UNION RESULT：UNION查询的查询结果。
- table：显示这行数据属于哪张表。
- type：显示查询使用了哪种类型，最优到最差的顺序为：system>const>eq_ref>ref>range>index>all。（一般来说，至少达到range）
  1. system：表中只有一行记录（相当于系统表），这是const类型的特例，平时不会出现，这个也可以忽略不计。
  2. const：表示通过索引一次找到，当你使用主键或者唯一索引的时候，就是const类型。因为只匹配一行数据，所以很快。将主键置为where中，MySQL就能将此查询转换为一个常量。
  3. eq_ref：触发条件：只匹配到一行的时候。除了system和const之外，这是最好的连接类型了。当我们使用主键索引或者唯一索引的时候，且这个索引的所有组成部分都被用上，才能是该类型。（唯一性索引扫描，对于每个索引键，表中只有一条记录与之匹配。常见于主键和唯一索引。）
  4. ref：触发条件：触发联合索引最左原则，或者这个索引不是主键，也不是唯一索引（换句话说，如果这个在这个索引基础之上查询的结果多于一行）。在对已经建立索引列进行=或者<=>操作的时候，ref会被使用到。与eq_ref不同的是匹配到了多行。
  5. range：只有给定范围内的行才能被检索，使用索引来查询出多行。 输出行中的类决定了会使用哪个索引。 key_len列表示使用的最长的 key 部分。 这个类型的ref列是NULL。
  6. index：index类型和ALL类型一样，区别就是index类型是扫描的索引树。以下两种情况会触发：
     - 如果索引是查询的覆盖索引，就是说索引查询的数据可以满足查询中所需的所有数据，则只扫描索引树，不需要回表查询。 在这种情况下，explain 的 Extra 列的结果是 Using index。仅索引扫描通常比ALL快，因为索引的大小通常小于表数据。
     - 全表扫描会按索引的顺序来查找数据行。使用索引不会出现在Extra列中。
  7. all：遍历全表得到匹配的行
  8. 其他特殊：index_merge：这是mysql对多个单列索引的优化，对结果集采用intersect并集操作

- possible_keys：显示可能应用于这张表的索引，一个或多个。查询涉及到的字段若存在索引，则该索引将被列出，但不一定被查询实际应用
- key：实际用到的索引。**查询中若使用了覆盖索引，则该索引和查询的select字段重叠。**
- key_len：表示索引中使用的字节数，可通过该列计算查询中使用的索引的长度。在不损失精度的情况下，长度越短越好。**key_len表示的是索引的最大可能长度，并非实际使用长度，即key_len是根据表定义计算而得，不是通过表内检索出的。**
- ref：显示索引的哪一列被使用了，如果可能的话，是一个常数。哪些列或常量被用于查找索引上的值。
- rows：根据表统计信息及索引的选用情况，大致估算出找到所需的记录所需要读取的行数。
- extra：包含在其他列中显示但十分重要的额外信息
  1. **Using filesort：说明MySQL会对数据使用一个外部的索引排序，而不是按照表内的索引顺序进行读取。MySQL无法利用索引完成的操作称为“文件排序”。**
  2. **Using temporary：使用了临时表保存中间结果，MySQL在对查询结果排序使用临时表。常见于排序order by和分组查询group by。**
  3. **Using index：表示相应的select操作使用了覆盖索引，避免访问了表的数据行。（优）如果同时出现using where，表明索引被用来执行索引键值的查找。如果没有同时出现using where，表明索引用来读取数据而非执行查找动作。**
  4. Using where：表明使用了where过滤。
  5. Using join buffer：使用了连接缓存。
  6. impossible where：where子句的值总是false，不能用来获取任何元组。
  7. distinct：优化distinct，在找到第一匹配的元组后停止找同样值的动作。

##### 索引失效

原因：

- 全值匹配（优）
- 最佳左前缀法则（如果索引了多列，要遵守最左前缀法则。指的是查询从索引的最左前列并且**不跳过索引的列**。
- 不在索引列上做任何的操作（计算，函数，类型转换），会导致索引失效而转向全表扫描。
- 存储引擎不能使用索引中范围条件右边的列。
- 尽量使用覆盖查询（索引列和查询列一致），减少select *。
- mysql在使用不等于的时候无法使用索引会导致全表扫描。
- is null, is not null也无法使用索引。
- like已通配符开头，MySQL索引失效会变成全表扫描。
- 字符串不加单引号索引失效。
- 少用or，用它来连接时会导致索引失效。

优化建议：

1. 对于单键索引，尽量选择针对当前query过滤性更好的索引。
2. 在选择组合索引的时候，当前query中过滤最好的字段在索引字段顺序中（位置越前越好）。
3. 在选择组合索引的时候，尽量选择可以包含当前query中的where子句中更多字段的索引。
4. 尽可能通过分析统计信息和调整query的写法来达到合适索引的目的。

##### 查询优化

order by关键字优化

- order by子句，尽量使用index方式排序（效率高，order by应该使用索引最左前列），避免使用filesort方式排序。（效率低）
- 尽可能在索引列上完成排序操作，遵照索引建的最佳左前缀。
- 如果不在索引列上，filesort有两种算法：MySQL就要启动双路排序和单路排序了。
  - 双路排序：读取行指针和order by列，对它们进行排序，然后扫描已经排序好的列表，按照列表中的值重新从列表中读取对应的数据输出。**从磁盘取排序字段，在buffer中进行排序，再从磁盘取其他字段。**两次I/O，相对更加耗时。
  - 单路排序：从磁盘读取查询需要的列，按照order by列在buffer中对它们进行排序，然后扫描排序后的列表进行输出，它的效率更快一点、避免第二次读取数据。并且把随机I/O变成了顺序I/O，但是他会使用更多的空间。
    - 单路排序的问题：在sort_buffer中，单路排序要比双路排序占很多空间，因为单路排序把所有的字段都取出，所以有可能取出的数据的总大小超出了sort_buffer的容量，导致每次只能读取sort_buffer容量大小的数据，进行排序(创建tmp文件，多路合并)，排完再取sort_buffer容量大小，再次排序…从而多次I/O。
    - 优化单路排序：增大sort_buffer_size参数，增大max_length_for_sort_data参数。

group by关键字优化

group by实质是先排序后进行分组，遵照索引建的最佳左前缀法则。当无法使用索引列时，增大sort_buffer_size参数，增大max_length_for_sort_data参数。where高于having，能写在where里的限定条件就不要去having限定了。

日常查询优化过程

1. 收到问题，诊断SQL
2. 开启慢查询日志，抓出执行的慢的SQL
3. 使用explain分析（基本上可以找到问题所在，但是如果还是没有摆平，我们的SQL在传输、网络、连接、死锁，需要进一步细粒度的查询和排查的时候就需要使用show profile）
4. show profile（还是解决的一般般）
5. 配合DBA 到my.cnf配置文件中对各种性能的参数调优和修改(基本上不需要我们来修改)

##### 慢查询日志

查看是否开启：SHOW VARIABLES LIKE '%slow_query_log%';

开启慢查询日志：SET GLOBAL slow_query_log =1

long_query_time:慢查询的时间阙值,默认是10s ，在刚修改的时候可能会不生效,要断开当前会话再连一次数据库就好了

log_output：慢查询日志输出目标，默认为file，即输出到文件。

**日志分析工具mysqldumpslow**

在生产环境中，如果要手工分析日志，查找、分析SQL，MySQL提供了日志分析工具mysqldumpslow。

-s, 是表示按照何种方式排序。

- c: 访问计数
- l: 锁定时间
- r: 返回记录
- t: 查询时间
- al:平均锁定时间
- ar:平均返回记录数
- at:平均查询时间

-t, 是top n的意思，即为返回前面多少条的数据；

-g, 后边可以写一个正则匹配模式，大小写不敏感的；

**show profile**

Show profile 是mysql 提供可以用来分析当前会话中语句执行的资源消耗情况。可以用于sql 调优的测量。默认情况下，参数处于关闭状态，并保存最近15次的运行结果。

- 查看profile是否开启：show variables like '%profi%';
- 开启profile记录功能：set profiling=on; #永久生效需要在配置文件my.cnf修改
- 查看执行了哪些命令：show profiles;
- 根据上一条命令结果的Query_ID查看某条query的执行过程：show profile cup,block io for query 11 #11 是Query_ID

show profile用法：

type
　　all 显示所有的开销信息
　　block io 显示块io相关的开销
　　context switches 上下文切换相关
　　cpu 显示cpu相关开销
　　ipc 显示发送和接收相关开销
　　memory 显示内存相关开销信息
　　page faults 显示页面错误相关开销
　　source 显示和Source_function,Source_file,Source_line相关的开销信息
　　swaps 显示交换次数相关开销的信息

出现以下信息时其中一个,说明必要要优化了
　　converting HEAP to MyISAM查询结果太大,内存都不够用了往磁盘上搬了
　　Creating tmp table 创建临时表,拷贝数据到临时表,用完再删除
　　copying to tmp table 把内存中临时表复制到磁盘,危险!!!
　　locked





*全局查询日志：千万不要在生产环境中开启这个功能*

#### MySQL锁机制  //TODO

#### MySQL主从复制 //TODO

#### MySql数据类型优化

选择数据结构原则：

- 选择占用空间小的数据类型
- 选择简单的类型
- 避免不必要的可空列

占用空间小的类型更节省硬件资源，如磁盘、内存和CPU。尽量使用简单的类型，如能用 int 就不用 char，因为后者的排序涉及到字符集的选择，比使用 int 复杂。

可空列使用更多的存储空间，如果在可空列上创建索引，MySQL需要额外的字节做记录。创建表时，默认都是可空，容易被开发者忽视，最好是手动改为不可空，如果要存储的数据确实不会有空值的话。

**整型**

- tinyint、smallint、mediumint、int、bigint

**小数**

- float
- double
- decimal

float和double就是通常意义上的float和double，前者使用32位存储数据，后者使用64位存储数据，和整型一样，为它们指定长度没什么卵用。

decimal类型比较复杂，支持精确计算，占用的空间也大，decimal使用每4个字节表示9个数字，如decimal(18,9)表示数字长度是18，其中小数位9个数字，整数部分9个数字，加上小数点本身，共占用9个字节。

考虑到decimal占用空间较多，以及精度计算很复杂，数据量大的时候可以考虑用bigint代替之，可以在持久化和读取前对真实数据进行一些缩放操作。

**字符串类型**

- varchar
- char
- varbinary
- binary
- blob
- text
- 枚举

varchar类型数据实际占用空间等于字符串的长度加上1个或2个用来记录字符串长度的字节（当row-format没有被设置为fixed时），varchar很节省空间。当表中某列字符串类型的数据长度差别较大时适合使用varchar。

char的实际占用空间是固定的，当表中字符串数据的长度相差无几或很短时适合使用chart类型。

与varchar和char对应的有varbinary和binary，后者存储的是二进制字符串，和前者相比，后者大小写敏感，不用考虑编码方式，执行比较操作时更快。

**需要注意的是**：虽然varchar(5)和varchar(200)在存储“hello”这个字符串时使用相同的存储空间，但并不意味着将varchar的长度设置太大不会影响性能，实际上，MySQL的某些内部计算，比如创建内存临时表时（某些查询会导致MySQL自动创建临时表），会分配固定大小的空间存放数据。

blob使用二进制字符串保存大文本，text使用字符保存大文本，InnoDB会使用专门的外部存储区来存放此类数据，数据行内仅存放指向他们的指针，此类数据不宜创建索引（要创建也只能正对字符串前缀创建），不过也不会有人这么干。

如果某列字符串大量重复且内容有限，可使用枚举代替，MySQL处理枚举时维护了一个“数字-字符串”表，使用枚举可以减少很多存储空间。

**时间类型**

- year
- date
- time
- datetime
- timestamp

datetime存储范围是1001到9999，精确到秒。timestamp存储1970年1月1日午夜以来的秒数，可以表示到2038年。**占用4个字节**，是datetime占用空间的一半。**timestamp表示的时间和时区有关**，***另外timestamp列还有个特性，执行insert或update语句时，MySQL会自动更新第一个类型为timestamp的列的数据为当前时间***。(很多表中都有设计有一列叫做UpdateTime，这个列使用timestamp倒是挺合适的，会自动更新，前提是系统不会使用到2038年。)

**主键类型的选择**：尽可能使用整型，整型占用空间少，还可以设置为自动增长。尤其别使用GUID，MD5等哈希值字符串作为主键，这类字符串随机性很大，由于InnoDB主键默认是聚簇索引列，所以导致数据存储太分散。

另外，InnoDB的二级索引列中默认包含主键列，如果主键太长，也会使得二级索引很占空间。

**特殊类型的数据**：存储IP最好使用32位无符号整型，MySQL提供了函数inet_aton()和inet_ntoa()进行IP地址的数字表示和字符串表示之间的转换。

#### 数据库如何进行分库分表

##### 数据切分

关系型数据库本身比较容易成为系统瓶颈，单机存储容量、连接数、处理能力都有限。当单表的数据量达到1000W或100G以后，由于查询维度较多，即使添加从库、优化索引，做很多操作时性能仍下降严重。此时就要考虑对其进行切分了，切分的目的就在于减少数据库的负担，缩短查询时间。

数据库分布式核心内容无非就是数据切分（Sharding），以及切分后对数据的定位、整合。数据切分就是将数据分散存储到多个数据库中，使得单一数据库中的数据量变小，通过扩充主机的数量缓解单一数据库的性能问题，从而达到提升数据库操作性能的目的。

###### 垂直切分

垂直切分常见有**垂直分库**和**垂直分表**两种。

**垂直分库**就是根据业务耦合性，将关联度低的不同表存储在不同的数据库。做法与大系统拆分为多个小系统类似，按业务分类进行独立划分。（每一个微服务单独使用一个数据库）

**垂直分表**是基于数据库中的"列"进行，某个表字段较多，可以新建一张扩展表，将不经常用或字段长度较大的字段拆分出去到扩展表中。通过"大表拆小表"，更便于开发与维护，**也能避免跨页问题**，MySQL底层是通过数据页存储的，一条记录占用空间过大会导致跨页，造成额外的性能开销。另外数据库以行为单位将数据加载到内存中，这样表中字段长度较短且访问频率较高，**内存能加载更多的数据**，命中率更高，**减少了磁盘IO，从而提升了数据库性能**。

###### 水平切分

当一个应用难以再细粒度的垂直切分，或切分后数据量行数巨大，存在单库读写、存储性能瓶颈，这时候就需要进行水平切分了。

水平切分分为**库内分表**和**分库分表**，库内分表只解决了单一表数据量过大的问题，但没有将表分布到不同机器的库上，因此对于减轻MySQL数据库的压力来说，帮助不是很大，大家还是竞争同一个物理机的CPU、内存、网络IO，最好通过分库分表来解决。

水平切分后同一张表会出现在多个数据库/表中，每个库/表的内容不同。几种典型的数据分片规则为：

1. **根据数值范围**（热点数据成为性能瓶颈）
2. **根据数值取模**（1.后期分片集群扩容时，需要迁移旧的数据。2.容易面临跨分片查询的复杂问题）

##### 分库分表带来的问题

1. **事务一致性问题**

2. **跨节点关联查询 join 问题**

   - 解决方法：
     - **全局表**
     - **字段冗余**：一种典型的反范式设计，利用空间换时间，为了性能而避免join查询。例如：订单表保存userId时候，也将userName冗余保存一份，这样查询订单详情时就不需要再去查询"买家user表"了。
     - **数据组装**：系统层面分两次层面，执行不同的查询然后组装在一起
     - **ER分片**：关系型数据库中，如果可以先确定表之间的关联关系，并将那些存在关联关系的表记录存放在同一个分片上，那么就能较好的避免跨分片join问题。

3. **跨节点分页、排序、函数问题**：跨节点多库进行查询时，会出现limit分页、order by排序等问题。分页需要按照指定字段进行排序，当排序字段就是分片字段时，通过分片规则就比较容易定位到指定的分片；当排序字段非分片字段时，就变得比较复杂了。需要先在不同的分片节点中将数据进行排序并返回，然后将不同分片返回的结果集进行汇总和再次排序，最终返回给用户。**这样的操作是很耗费CPU和内存资源的，所以页数越大，系统的性能也会越差。**

   在使用Max、Min、Sum、Count之类的函数进行计算的时候，也需要先在每个分片上执行相应的函数，然后将各个分片的结果集进行汇总和再次计算，最终将结果返回。

4. **全局主键避重问题**（分片情况下，分区数据库生成的自增id无法保持全局唯一）：

   - 解决方案：

     - **UUID（UUID非常长，会占用大量的存储空间；另外，作为主键建立索引和基于索引进行查询时都会存在性能问题，在InnoDB下，UUID的无序性会引起数据位置频繁变动，导致分页）**

     - **结合数据库维护主键ID表**

       此方案较为简单，但缺点也明显：存在单点问题，强依赖DB，当DB异常时，整个系统都不可用。配置主从可以增加可用性，但当主库挂了，主从切换时，数据一致性在特殊情况下难以保证。

       ```sql
       REPLACE INTO sequence (stub) VALUES ('a');  //stub列设置为唯一索引，避免sequence表过大
       SELECT LAST_INSERT_ID();
       ```

     - **Snowflake分布式自增ID算法**（优点：不依赖第三方系统，稳定性和效率较高，理论上QPS约为409.6w/s（1000*2^12），并且整个分布式系统内不会产生ID碰撞；可根据自身业务灵活分配bit位。缺点：强依赖机器时钟，如果时钟回拨，则可能导致生成ID重复。）

5. **数据迁移、扩容问题**：如果采用数值范围分片，只需要添加节点就可以进行扩容了，不需要对分片数据迁移。如果采用的是数值取模分片，则考虑后期的扩容问题就相对比较麻烦。

##### 什么时候需要切分

- **能不切分尽量不要切分**（升级硬件、升级网络、读写分离、索引优化等等）
- **数据量过大，正常运维影响业务访问**
- **随着业务发展，需要对某些字段垂直拆分**：用户模块在项目初始阶段，这种设计是满足简单的业务需求的，也方便快速迭代开发。而当业务快速发展时，用户量从10w激增到10亿，用户非常的活跃，每次登录会更新 last_login_name 字段，使得 user 表被不断update，压力很大。而其他字段：id, name, personal_info 是不变的或很少更新的，此时在业务角度，就要将 last_login_time 拆分出去，新建一个 user_time 表。
- **数据量快速增长**
- **安全性和可用性**：利用水平切分，当一个数据库出现问题时，不会影响到100%的用户，每个库只承担业务的一部分数据，这样整体的可用性就能提高。

##### 水平切分后非主键id的查询怎么优化

对于用户侧，可以采用"建立非uid属性到uid的映射关系"的方案；对于运营侧，可以采用"前台与后台分离"的方案。

###### **建立非uid属性到uid的映射关系**：

1. **映射关系**

   例如：login_name不能直接定位到数据库，可以建立login_name→uid的映射关系，用索引表或缓存来存储。当访问login_name时，先通过映射表查询出login_name对应的uid，再通过uid定位到具体的库。

   映射表只有两列，可以承载很多数据，当数据量过大时，也可以对映射表再做水平切分。**这类kv格式的索引结构，可以很好的使用cache来优化查询性能，而且映射关系不会频繁变更，缓存命中率会很高。**

2. **基因法**

   分库基因：假如通过uid分库，分为8个库，采用uid%8的方式进行路由，此时是由uid的最后3bit来决定这行User数据具体落到哪个库上，那么这3bit可以看为分库基因。

   上面的映射关系的方法需要额外存储映射表，按非uid字段查询时，还需要多一次数据库或cache的访问。如果想要消除多余的存储和查询，可以通过f函数取login_name的基因作为uid的分库基因。生成uid时，参考上文所述的分布式唯一ID生成方案，再加上最后3位bit值=f(login_name)。当查询login_name时，只需计算f(login_name)%8的值，就可以定位到具体的库。不过这样需要提前做好容量规划，预估未来几年的数据量需要分多少库，要预留一定bit的分库基因。

###### **前台与后台分离**

而对于运营侧，很多批量分页且条件多样的查询，这类查询计算量大，返回数据量大，对数据库的性能消耗较高。此时，如果和用户侧共用同一批服务或数据库，可能因为后台的少量请求，占用大量数据库资源，而导致用户侧访问性能降低或超时。

运营侧后台业务抽取独立的service和db，解决和前台业务系统的耦合。**由于运营侧对可用性、一致性的要求不高，可以不访问实时库，而是通过binlog异步同步数据到运营库进行访问**。在数据量很大的情况下，还可以使用ES搜索引擎或Hive来满足后台复杂的查询方式。

#### 面试

##### 为什么要垂直分表

通过将重要字段单独剥离除一张小表，让每一页能够容纳更多的行，进而缩小数据扫描的范围，达到提高执行效率的目的。比如说有一亿条数据，MySql一页存储16k的row，那么这一亿条数据将需要625万个也才能存储下，以后每次检索时都要搜索着625万个页，如果我们垂直分表的话，把热点where查询的列单独剥离存放在小表里，那么一行的数据就大大减少，只需要检索几十万就可以了。

##### 什么情况需要垂直分表

单表数据量未来可能千万，字段超过20个，且包含了超长的varchar,CLOB,BLOB等字段

##### 多级缓存架构

为了提高效率，很多公司都部署了多级缓存架构。

从浏览器/客户端开始请求数据，通过 HTTP 配合 CDN（内容分发技术，因为如果我们请求的服务器很远，在传输过程中可能会有网络延迟，所以远程服务器可以通过CDN将静态资源分发到最近的服务器） 获取数据的变更情况，到达代理服务器（Nginx）可以通过反向代理获取静态资源。

再往下来到应用服务器可以通过进程内（堆内）缓存（ehcache），分布式缓存（redis）等递进的方式获取数据。如果以上所有缓存都没有命中数据，才会回源到数据库。

缓存的请求顺序是：用户请求 → HTTP 缓存 → CDN 缓存 → 代理服务器缓存 → 进程内缓存 → 分布式缓存 → 数据库。

##### 什么情况下需要多级缓存

1. 缓存的数据是稳定的
2. 瞬时可能会产生极高并发的场景（整点秒杀，股市开盘，可以通过预热）
3. 一定程序上允许数据不一致（多级缓存必然会存在数据不一致的问题，我们可以通过RabbitMQ来保证最终一致性）