#### this逃逸问题

this逃逸是指在构造函数返回之前其他线程就持有该对象的引用. 调用尚未构造完全的对象的方法可能引发令人疑惑的错误（this逃逸经常发生在构造函数中启动线程或注册监听器时）。

**解决方案**

JUC包下Executor框架

Executor框架包括：线程池，Executor，Executors，ExecutorService，CompletionService，Future，Callable等。

**Executor**：一个接口，其定义了一个接收Runnable对象的方法executor，其方法签名为executor(Runnable command),该方法接收一个Runable实例，它用来执行一个任务，任务即一个实现了Runnable接口的类，一般来说，Runnable任务开辟在新线程中的使用方法为：new Thread(new RunnableTask())).start()，但在Executor中，可以使用Executor而不用显示地创建线程：executor.execute(new RunnableTask()); // 异步执行

**ExecutorService**：**是一个比Executor使用更广泛的子类接口**，其提供了生命周期管理的方法，**返回 Future 对象**，以及可跟踪一个或多个异步任务执行状况返回Future的方法；可以调用ExecutorService的shutdown（）方法来平滑地关闭 ExecutorService，调用该方法后，将导致ExecutorService停止接受任何新的任务且等待已经提交的任务执行完成(已经提交的任务会分两类：一类是已经在执行的，另一类是还没有开始执行的)，当所有已经提交的任务执行完毕后将会关闭ExecutorService。因此我们一般用该接口来实现和管理多线程。

通过 ExecutorService.submit() 方法返回的 Future 对象，可以调用isDone（）方法查询Future是否已经完成。当任务完成时，它具有一个结果，你可以调用get()方法来获取该结果。你也可以不用isDone（）进行检查就直接调用get()获取结果，在这种情况下，get()将阻塞，直至结果准备就绪，还可以取消任务的执行。Future 提供了 cancel() 方法用来取消执行 pending 中的任务。

**Executors类**： 主要用于提供线程池相关的操作，提供了一系列工厂方法用于创建线程池，返回的线程池都实现了ExecutorService接口。

#### //kmp算法

#### 如何把可重入锁变为不可重入锁

这个可重入的概念就是，拿到锁的线程可以多次以不用的方式再次访问临界资源而不出现死锁的情况。经典之处在于判断了**当前申请锁的线程是否是加锁的线程**。如果是，则拥有**重入**的能力。

```
不可重入
public class Lock{
     private boolean isLocked = false;
     public synchronized void lock() throws InterruptedException{
         while(isLocked){    
             wait();
         }
         isLocked = true;
     }
     public synchronized void unlock(){
         isLocked = false;
         notify();
    }
}
这里的锁是不可重入锁，执行A方法时，A方法获取lock锁之后，需要调用B方法，但是此时该对象的对象锁已经被方法A拿走了，B方法得不到需要的对象锁，只能等待A方法将对象锁释放，而A方法又必须调用完B方法才能释放对象锁，这样子就会出现死锁，这种很笨的锁就叫做不可重入锁，上述情况就是这种锁可能会出现缺陷。

可重入
public class Lock{
    boolean isLocked = false;
    Thread  lockedBy = null;
    int lockedCount = 0;
    public synchronized void lock()
            throws InterruptedException{
        Thread thread = Thread.currentThread();
        //判断：当临界资源已被锁上，但当前请求锁的线程不是之前锁上临界资源的线程。那么当前请求锁的线程需要等待。
        while(isLocked && lockedBy != thread){
            wait();
        }
        isLocked = true;
        lockedCount++;
        lockedBy = thread;
    }
    public synchronized void unlock(){
        if(Thread.currentThread() == this.lockedBy){
            lockedCount--;
            if(lockedCount == 0){
                isLocked = false;
                notify();
            }
        }
    }
}

```

#### 线程数参数优化

为了说明合理设置的条件，我们首先确定有以下几个相关参数：

1. tasks，程序每秒需要处理的最大任务数量（假设系统每秒任务数为100~1000）
2. tasktime，单线程处理一个任务所需要的时间（每个任务耗时0.1秒）
3. responsetime，系统允许任务最大的响应时间（每个任务的响应时间不得超过2秒）

**corePoolSize：**

每个任务需要tasktime秒处理，则每个线程每秒可处理1/tasktime个任务。系统每秒有tasks个任务需要处理，则需要的线程数为：tasks/(1/tasktime)。即tasks*tasktime个线程数。

具体数字最好根据8020原则，即80%情况下系统每秒任务数，若系统80%的情况下任务数小于200，最多时为1000，则corePoolSize可设置为20。

**queueCapacity：**任务队列的长度。任务队列的长度要根据核心线程数，以及系统对任务响应时间的要求有关。队列长度可以设置为(corePoolSize/tasktime)*responsetime： (20/0.1)*2=400，即队列长度可设置为400。

比如：LinkedBlockingQueue queue = new LinkedBlockingQueue();
这实际上是将队列长度设置为Integer.MAX_VALUE，将会导致线程数量永远为corePoolSize，再也不会增加，当任务数量陡增时，任务响应时间也将随之陡增。

**maxPoolSize：**最大线程数

当系统负载达到最大值时，核心线程数已无法按时处理完所有任务，这时就需要增加线程。每秒200个任务需要20个线程，那么当每秒达到1000个任务时，则需要(1000-queueCapacity)*(20/200)，即60个线程，可将maxPoolSize设置为60。

**keepAliveTime:**

keepAliveTiime设定值可根据任务峰值持续时间来设定。

以上关于线程数量的计算并没有考虑CPU的情况。若结合CPU的情况，比如，当线程数量达到50时，CPU达到100%，则将maxPoolSize设置为60也不合适，此时若系统负载长时间维持在每秒1000个任务，则超出线程池处理能力，应设法降低每个任务的处理时间(tasktime)。

#### 线程数量的设计

cpu密集型的任务 一般设置 线程数 = 核心数N + 1

io密集型的任务 一般设置 线程数 = 核心数N*2 + 1

如果都存在，则分开两个线程池

实际应用中 线程数 = (（线程CPU时间+线程等待时间）/ 线程CPU时间 ) * 核心数N

#### 多线程

多线程可以充分利用cpu资源，提高cpu利用率，可以将耗时的其他操作放在后台执行。但是也会导致性能问题（线程的上下文切换），线程多也会占用内存。

多线程也会产生一些并发问题，比如1.对于共享数据的修改读取的脏读等。2.指令重排，致使代码的执行顺序不是我们期望的那样。

#### **JVM加载过程**

Java源代码被编译成class字节码，最终需要加载到虚拟机中才能运行。整个加载过程包括：加载、验证、准备、解析、初始化5个阶段，其中准备、验证、解析为链接的子阶段。

##### **加载：**

1. 通过一个类的全限定名获取描述此类的二进制字节流；
2. 将这个字节流所代表的静态存储结构保存为方法区的运行时数据结构；
3. 在java堆中生成一个代表这个类的java.lang.Class对象，作为访问方法区的入口；

虚拟机设计团队把加载动作放到JVM外部实现，以便让应用程序决定如何获取所需的类，实现这个动作的代码称为“类加载器”，JVM提供了3种类加载器：

1. 启动类加载器（Bootstrap ClassLoader）：负责加载 JAVA_HOME\lib 目录中的，或通过-Xbootclasspath参数指定路径中的，且被虚拟机认可（按文件名识别，如rt.jar）的类。
2. 扩展类加载器（Extension ClassLoader）：负责加载 JAVA_HOME\lib\ext 目录中的，或通过java.ext.dirs系统变量指定路径中的类库。
3. 应用程序类加载器（Application ClassLoader）：负责加载用户路径（classpath）上的类库。

基于类加载器，通过双亲委派模型进行类的加载

**双亲委派模型工作过程：当一个类加载器收到类加载任务，优先交给其父类加载器去完成，因此最终加载任务都会传递到顶层的启动类加载器，只有当父类加载器无法完成加载任务时，才会尝试执行加载任务。**

**双亲委派模型有什么好处？
比如位于rt.jar包中的类java.lang.Object，无论哪个加载器加载这个类，最终都是委托给顶层的启动类加载器进行加载，确保了Object类在各种加载器环境中都是同一个类。**

全盘负责委托机制 

“全盘负责”是指当一个ClassLoder装载一个类时，除非显示的使用另外一个ClassLoder，该类 所依赖及引用的类也由这个ClassLoder载入。

##### 验证：

为了确保Class文件符合当前虚拟机要求，需要对其字节流数据进行验证，主要包括格式验证、元数据验证、字节码验证和符号引用验证。

- 格式验证：验证字节流是否符合class文件格式的规范，并且能被当前虚拟机处理，如是否以魔数0xCAFEBABE开头、主次版本号是否在当前虚拟机处理范围内、常量池是否有不支持的常量类型等。只有经过格式验证的字节流，才会存储到方法区的数据结构，剩余3个验证都基于方法区的数据进行。
- 元数据验证：对字节码描述的数据进行语义分析，以保证符合Java语言规范，如是否继承了final修饰的类、是否实现了父类的抽象方法、是否覆盖了父类的final方法或final字段等。
- 字节码验证：对类的方法体进行分析，确保在方法运行时不会有危害虚拟机的事件发生，如保证操作数栈的数据类型和指令代码序列的匹配、保证跳转指令的正确性、保证类型转换的有效性等。
- 符号引用验证：为了确保后续的解析动作能够正常执行，对符号引用进行验证，如通过字符串描述的全限定名是都能找到对应的类、在指定类中是否存在符合方法的字段描述符等。

##### 准备：

在准备阶段，为类变量（static修饰）在方法区中分配内存并设置初始值。

> private static int var = 100;

准备阶段完成后，var 值为0，而不是100。在初始化阶段，才会把100赋值给var。（存在特殊情况，当给常量（static、final）赋值时，在编译阶段就会为常量生成ConstantValue属性，在准备阶段就会根据该属性将常量赋值）

##### 解析：

解析阶段是将常量池中的**符号引用**替换为**直接引用**的过程

符号引用：符号引用使用一组符号来描述所引用的目标，可以是任何形式的字面常量，定义在Class文件格式中。

直接引用：直接引用可以是直接指向目标的指针、相对偏移量或则能间接定位到目标的句柄。

##### 初始化：

初始化阶段是执行类构造器<clinit>方法的过程，<clinit>方法由类变量的赋值动作和静态语句块按照在源文件出现的顺序合并而成，该合并操作由编译器完成。

- <clinit>方法对于类或接口不是必须的，如果一个类中没有静态代码块，也没有静态变量的赋值操作，那么编译器不会生成<clinit>；
- <clinit>方法与实例构造器不同，不需要显式的调用父类的<clinit>方法，虚拟机会保证父类的<clinit>优先执行；
- 为了防止多次执行<clinit>，虚拟机会确保<clinit>方法在多线程环境下被正确的加锁同步执行，如果有多个线程同时初始化一个类，那么只有一个线程能够执行<clinit>方法，其它线程进行阻塞等待，直到<clinit>执行完成。
- 注意：执行接口的<clinit>方法不需要先执行父接口的<clinit>，只有使用父接口中定义的变量时，才会执行。

**关于类加载器的一些想法：**

类加载器的加载逻辑 首先windows下java.exe会调用底层jvm.dll文件创建Java虚拟机（C++），创建一个引导类加载器实例也就是bootstarpClassLoader（C++），C++调用Java代码创建JVM启动器的实例sun.misc.Launcher（由引导类加载器加载，可用于创建其他的加载器，原理是因为Launcher构造函数就已经初始化了ExtClassLoader和AppClassLoader）。这三个顶层加载器很重要，那具体是怎么加载的呢，这就要提到**双亲委派机制**，简单的说就是加载时从下往上寻找目标类，找到的话加载，如果所有的父加载器都找不到加载类的路径那就在自己的类路径下寻找并加载（也就是loadClass和findClass逻辑）。可能到这里就有疑问了，为什么要设计这种双亲委派机制呢，我揣测这样可以防止核心API库被随意的篡改（比如我们自定义了一个java.lang.String类实际实际上并不会加载这个类，加载时会委托引导类加载器加载JRE下lib目录下的类，当然java虚拟机也会报错因为高版本的java不允许定义java.lang开头的包），当然也可以避免类的重复加载（父加载器加载了一遍，没必要子加载器再加载了，保证了加载类的唯一性）。如果非要加载自定义的String类呢，这就需要打破双亲委派机制了，网上可能会说继承classLoader类然后重写loadClass方法和findClass方法，这不完全对这样确实可以打破双亲委派机制但是虚拟机还是会报错java.lang.SecurityException: Prohibited package name: java.lang（不得不说Java优化的越来越好了）。当然可以利用打破双亲委派机制来用我们自定义的加载器加载自定义的类（当然要注意改写loadClass是最好判断加载的类如果不是我们指定包下的类就调用父类加载器AppClassLoader从而回到双亲委派机制，这样做是因为加载一个类时会先加载它的父类Object类，如果不想报错的话）。

还有Tomcat也有它的打破双亲委派机制的方法

![image-20210911193501211](C:\Users\wuxiaowen\AppData\Roaming\Typora\typora-user-images\image-20210911193501211.png)

WebappClassLoader

各个Webapp私有的类加载器，加载路径中的class只对当前 Webapp可见，比如加载war包里相关的类，每个war包应用都有自己的 WebappClassLoader，实现相互隔离，比如不同war包应用引入了不同的spring版本， 这样实现就能加载各自的spring版本；

JasperLoader

而JasperLoader的加载范围仅仅是这个JSP文件所编译出来的那一个.Class文件，它出现的目的 就是为了被丢弃：当Web容器检测到JSP文件被修改时，会替换掉目前的JasperLoader的实例， 并通过再建立一个新的Jsp类加载器来实现JSP文件的热加载功能。

**每个 webappClassLoader加载自己的目录下的class文件，不会传递给父类加载器，打破了双亲委派机制。**

#### JVM相关

> 虚拟机栈：jvm为每一个线程分配一个虚拟机栈，Java 方法都是通过 Java 虚拟机栈来实现调用和执行过程的（需要程序技术器、堆、元空间内数据的配合），Java虚拟机栈中出栈和入栈的元素被称为栈帧，可以说线程对应虚拟机栈，栈帧对应方法。虚拟机栈通过 pop 和 push 的方式，对每个方法对应的活动栈帧进行运算处理，方法正常执行结束，肯定会跳转到另一个栈帧上。在执行的过程中，如果出现了异常，会进行异常回溯，返回地址通过**异常处理表**确定。栈帧则包括局部变量表，操作数栈，动态链接以及方法出口。

- 局部变量表：存放方法参数和方法内部定义的局部变量的区域。并且局部变量表所需的内存空间在编译器完成分配，在运行期间不会改变局部变量表的大小（**如果是Java8大数据类型，则存储在局部变量表中，如果是引用数据类型，局部变量表中存储的是引用，实例存储在堆空间中**）
- 操作数栈：Java 虚拟机的解释执行引擎称为“基于栈的执行引擎”，其中所指的“栈”就是操作数栈。为方法创建一个栈帧时，会在栈帧中创建一个操作数栈，保证方法内的指令完成工作。**方法内的变量运行时，会把局部变量压入操作数栈进行操作，并把计算结果压栈**
- 动态链接：每个栈帧中包含一个在常量池中对当前方法的引用， 目的是支持方法调用过程的动态连接（static静态方法是在类加载过程中进行调用，也就是静态链接）。
- 方法返回地址：方法退出的过程要将该栈帧弹出虚拟机栈，返回至方法调用的位置，退出可能有三种方式：
  - 返回值压入上层调用栈帧
  - 异常信息抛给能够处理的栈帧
  - PC 计数器指向方法调用后的下一条指令

**Code Cache:** JVM 代码缓存是 JVM 将其字节码存储为本机代码的区域 。我们将可执行本机代码的每个块称为 nmethod。该 nmethod 可能是一个完整的或内联 Java 方法。

java内存五大区域不用说了。先总结一下常用的JVM参数设置，**-XX：MaxMetaspaceSize： 设置元空间最大值， 默认是-1， 即不限制， 或者说只受限于本地内存大小。-XX：MetaspaceSize： 指定元空间触发Fullgc的初始阈值(元空间无固定初始大小)**， 以字节为单位，默认是21M，达到该值就会触发 full gc进行类型卸载，**同时收集器会对该值进行调整： 如果释放了大量的空间， 就适当降低该值； 如果释放了很少的空间， 那么在不超过-XX：MaxMetaspaceSize（如果设置了的话） 的情况下， 适当提高该值。**（由于调整元空间的大小需要Full GC，这是非常昂贵的操作，如果应用在启动的时候发生大量Full GC，通常都是由于永久代或元空间发生 了大小调整，基于这种情况，一般建议在JVM参数中将MetaspaceSize和MaxMetaspaceSize设置成一样的值，并设置得比初始值要大， 对于8G物理内存的机器来说，一般我会将这两个值都设置为256M。）

先说一下JVM创建对象的流程，当我们使用new指令来创建一个对象的时候先**检查是否能在常量池中定位到这个类的符号引用，并检查这个符号引用代表的类是否已被加载、解析和初始化，没有则执行加载过程**，之后为对象分配内存，而为对象划分内存的方法主要有两个，一个是指针碰撞（默认），另一个是空闲列表。这个时候就出现了一个问题，在高并发的情况下，可能出现正在给对象A分配内存，指针还没来得及修改，对象B又同时使用了原来的指针来分配内存的情况。JVM解决此并发问题的方法就是**CAS搭配TLAB（本地线程分配缓冲，为每个线程在Java堆里预先分配一小块内存 默认开启 -XX：+/-UseTLAB）**。之后就是给**对象初始化零值**（当然不包括对象头，对象头是个重点），这个操作如果之前使用了TLAB的话可以提前在TLAB分配时进行，目的就是为了保证对象的实例字段在Java代码中不赋值就可以使用。接着就是**设置对象头**，对象分为三个部分，对象头，实例数据以及填充数据。对象头分为Mark Word标记字段（GC分代年龄，哈希值，锁状态标志，线程持有锁，偏向锁id等），Klass Pointer类型指针(开启压缩站4字节，是类的元数据指针)，**‐XX:+UseCompressedOops 默认开启的压缩所有指针，‐XX:+UseCompressedClassPointers 默认开启的压缩对象头里的类型指针Klass Pointer**（从JVM6开始就支持指针压缩，开启指针压缩的目的，应该是在64位平台的HotSpot中使用32位指针，内存使用会多出1.5倍左右，使用较大指针在主内存和缓存之间移动数据， **占用较大宽带，同时GC也会承受较大压力**），还有数组长度（4字节，只有数组对象才有），最后是执行init初始化方法，为对象属性赋值。

当所有对象都在堆中分配时，会给gc带来较大的压力，间接影响了应用的性能，为了减少在堆中分配的数量，JVM通过**逃逸分析（就是分析对象动态作用域，当一个对象在方法中被定义后，它可能被外部方法所引用，例如作为调用参数传递到其他地方中。）**来优化，通过将不会逃逸的对象放在栈上分配，随着栈帧的出栈销毁，这样就减轻了gc的压力，**-XX:+DoEscapeAnalysis**默认开启。并且通过**标量替换**的方式分配在栈上，变量替换就是通过逃逸分析确定该对象不会被外部访问，并且对象可以被进一步分解时，**JVM不会创建该对象**，而是将该对象成员变量分解若干个被这个方法使用的成员变量所代替（分配在栈帧或寄存器），这样就不会因为没有一大块连续空间导致对象内存不够分配。**-XX:+EliminateAllocations**，JDK7后默认开启。

上面是在栈中创建对象的情况，当然大多数对象还是在堆Eden区中分配，当Eden区没有空间了将发起一次minor gc。其中Eden区和survior区的比例是8:1:1。这个比例开发中很合适，因为新生代gc的频率很快，对象的存活时间很短，所以我们应该让Eden区足够大，survivor区够用即可，**-XX:+UseAdaptiveSizePolicy(默认开启)**，会导致这个8:1:1比例自动变化。JVM本身有一些规定，比如说**大对象直接进入老年代**，JVM参数 **-XX:PretenureSizeThreshold 可以设置大对象的大小**，如果对象超过设置大小会直接进入老年代，不会进入年轻代，这个参数只在 Serial 和ParNew两个收集器下有效。这样避免了为大对象分配内存时的复制操作。还有就是**长期存活的对象将进入老年代**，什么算长期存活？看过c++hotspot部分代码，我们就可以发现虚拟机为我们定义了一个**age年龄计数器**，如果对象在 Eden 出生并经过第一次 Minor GC 后仍然能够存活，并且能被 Survivor 容纳的话，将被移动到 Survivor 空间中，并将对象年龄设为1。对象在 Survivor 中每熬过一次 MinorGC，年龄就增加1岁，当它的年龄增加到一定程度 （默认为15岁，CMS收集器默认6岁，不同的垃圾收集器会略微有点不同），就会被晋升到老年代中。对象晋升到老年代的年龄阈值，可以通过参数 **-XX:MaxTenuringThreshold** 来设置。那么对象的动态年龄怎么判断呢，是这样的，观察动态年龄计算的源码，**代码中有一个TargetSurvivorRatio的值，-XX:TargetSurvivorRatio 目标存活率，默认为50%，通过这个比率来计算一个期望值，desired_survivor_size ，然后用一个total计数器，累加每个年龄段对象大小的总和，当total大于desired_survivor_size 停止，然后用当前age和MaxTenuringThreshold 对比找出最小值作为结果。**当一批对象的总大小大于这块survivor区域内存大小的百分之50时，那么此时**大于等于这批对象年龄最大值的对象**，就可以直接进入老年代了。这个规则其实是**希望那些可能是长期存活的对象，今早进入老年代。对象的动态年龄判断机制一般是在minor gc之后触发的。**为什么是在minor gc之后触发的，**因为如果本次GC时就以这个年龄作为晋升标准，那survivor区永远也超不过默认的50%了，更别说触发分配担保机制。**谈到了分配担保机制，什么是老年代空间分配担保机制？年轻代每次minor gc之前JVM都会计算当前老年代的剩余可用空间，如果说这个可用空间**大于**年轻代里现有的所有对象大小之和（**包括垃圾对象**），就直接进行minor gc，不然就开始判断“**-XX:-HandlePromotionFailure**”(jdk1.8默认就设置了)的参数是否设置了，如果存在这个参数，就会看看老年代可用内存大小，是否大于之前每次minor gc后进入老年代的对象**平均大小。**如果上一步的结果是小于或者没有设置这个参数的话，那么就触发一次full gc，对老年代和年轻代一起回收一次垃圾，如果回收完还是没有内存可以分配的话就会抛出“OOM”异常。

上面说了JVM的一些规定（大对象直接进入老年代，长期存活的对象将进入老年代以及对象动态年龄判断和老年代空间分配担保机制），接下来总结一下对象是怎么内存回收的，回收之前我们得先判断这个对象已经死亡，我们学习的方法就是**引用计数法**和**可达性分析算法**。什么是引用计数法，简单的说就是JVM给对象维护了一个引用计数器，每当有一个对象引用到它时，计数器就加一，引用失效的话计数器减一，为0时就判断这个对象不在使用。**这个方法虽然简单高效，但是有一个缺点就是它无法解决对象之间循环引用的问题，所以目前主流的虚拟机中并没有选择这个算法来管理内存**，可达性分析算法就是以GC roots对象作为起点，从这些节点开始向下搜索引用的对象，找到的对象都标记为非垃圾对象，其余未标记的对象都是垃圾对象。GC roots根节点包括线程栈的本地变量，静态变量以及本地方法栈的对象等等。说到引用，就得提高Java的四种引用类型：强引用，软引用（**软引用可用来实现内存敏感的高速缓存**，如果内存足够，就可以把缓存放在内存中，加快访问速度，如果内存不够了，缓存就会被回收掉，比如浏览器的回退操作，之前学习的时候无法理解软引用的特性没有啥用，现在想想汗颜。。。。），弱引用以及虚引用。弱引用的作用就是如果一个对象是偶尔的使用，并且希望在使用时随时就能获取到，但又不想影响此对象的垃圾收集，那么就可以将对象修饰为为弱引用类型。**弱引用的isEnQueued方法返回对象是否被垃圾回收器标记，所以弱引用还可以用于监控对象是否已经被垃圾回收器标记为即将回收的垃圾。**或者说你想引用一个对象，但是这个对象有自己的生命周期，如果不想介入这个对象的生命周期，这个时候就可以用弱引用。最后一种强度最弱的虚引用，虚引用的话往往配合引用队列使用，**当垃圾回收器准备回收一个对象时， 如果发现它还有虚引用，就会把这个虚引用加入到与之关联的引用队列中。**所以我们可以通过判断队列中是否加入了虚引用来了解是否将要被垃圾回收。如果程序发现某个虚引用已经被加入到引用队列，那么就可以在所引用的对象回收之前采取必要的操作（**finalize()方法**），finalize()方法最终判定对象是否存活，首先可达性分析算法中不可达的对象，也并非是非死不可，宣告对象死亡之前，至少要经历**两次标记过程。**标记的前提是**对象在进行可达性分析后发现没有与GC Roots相连接的引用链。**第一次标记进行一次筛选，筛选的条件就是判断此对象是否有必要执行finalize方法，如果对象没有覆盖此方法，那么对象直接被回收。第二次标记，如果此对象覆盖了finalize方法的话并且在该方法将此对象与任何一条引用链建立关联的话，就可以避免被回收，否则真的就要被回收了。我们之前判断了怎么判断这个对象无用，那么类是怎么判断无用的呢？要满足三个条件：①该类所有的实例都已经被回收，也就是 Java 堆中不存在该类的任何实例。②加载该类的 ClassLoader 已经被回收。③该类对应的 java.lang.Class 对象没有在任何地方被引用，无法在任何地方通过反射访问该类的方法。

上面说了一大堆关于判断对象是否为垃圾对象，以及JVM垃圾回收的各种策略和优化，现在总结一下JVM是怎么回收垃圾对象的。首先JVM的垃圾收集算法都是基于分代收集理论的，年轻代每次收集都有大量的对象死去，所以可以选择复制算法，老年代的存活率高，可以选择标记清除和标记整理算法。**复制算法**的原理是将内存分为两块，每次使用一块，就将存活的对象复制到另外一块，然后把这一块的空间清理掉。**标记清除**就是两阶段先标记存活的对象，然后将未存活的对象回收，它是最基础的收集算法，比较简单，也会带来两个明显的问题，**效率问题（如果标记的对象太多，效率不高）和空间问题（标记清除后会产生大量不连续的碎片）。**然后是另一种标记算法，**标记整理**，先标记，然后让存活的对象向一端移动，然后清理掉边界外的内存。具体的算法都有具体的实现，常见的收集器有 **Serial收集器(-XX:+UseSerialGC -XX:+UseSerialOldGC)**，特点是单线程，但是会有stw问题，这种收集器新生代采用复制算法而老年代采用标记整理算法，与其他收集器相比的优点就是简单而高效。**Serial Old收集器**是Serial收集器的老年代版本，它主要有两大用途：一种用途是在JDK1.5 以及以前的版本中与Parallel Scavenge收集器搭配使用，另一种用途是作为CMS收集器的后备方案。第二个组合就是**Parallel Scavenge收集器(-XX:+UseParallelGC(年轻代),-XX:+UseParallelOldGC(老年代))**，Parallel收集器其实就是Serial收集器的多线程版本，默认的收集线程数跟cpu核数相同，当然也可以用参数**(- XX:ParallelGCThreads)**指定收集线程数，但是一般不推荐修改。**Parallel Scavenge收集器关注点是吞吐量（高效率的利用CPU）。CMS等垃圾收集器的关注点更多的是用户线程的停顿时间（提高用户体验）。所谓吞吐量就是CPU中用于运行用户代码的时间与CPU总消耗时间的比值。** 新生代采用复制算法，老年代采用标记-整理算法。Scavenge收集器提供了很多参数供用户找到最合适的停顿时间或最大吞吐量，如果对于收集器运作不太了解的话，可以选择把内存管理优化交给虚拟机去完成也是一个不错的选择。**Parallel Old收集器是Parallel Scavenge收集器的老年代版本。**使用多线程和“标记-整理”算法。在注重吞吐量以及 CPU资源的场合，都可以优先考虑 Parallel Scavenge收集器和Parallel Old收集器(JDK8默认的新生代和老年代收集器)。

还有一种组合为 ParNew收集器(-XX:+UseParNewGC)ParNew收集器其实跟Parallel收集器很类似，区别主要在于它可以和CMS收集器配合使用。 新生代采用复制算法，老年代采用标记-整理算法。除了Serial收集器外，只有它能与CMS收集器配合工作。**CMS收集器(-XX:+UseConcMarkSweepGC(old))**，CMS（Concurrent Mark Sweep）收集器是一种以获取最短回收停顿时间为目标的收集器。它非常符合在注重用户体验的应用上使用，它是HotSpot虚拟机第一款真正意义上的并发收集器，它第一次实现了让垃圾收集线程与用户线程 （基本上）同时工作。整个过程分为4个阶段，初始标记，并发标记，重新标记（这个阶段的停顿时间一般会比初始标记阶段的时间稍长，远远比并发标记阶段时间短。**主要用到三色标记里的增量更新算法做重新标记**。），并发清理（这个阶段如果有新增对象会被标记为黑色不做任何处理），最后并发重置（重置本次GC过程中的标记数据）。主要优点：并发收集、低停顿。当然也有几个明显的缺点：①对CPU资源敏感（会和服务抢资源）；②无法处理浮动垃圾(在并发标记和并发清理阶段又产生垃圾，这种浮动垃圾只能等到下一次gc再清理了)；③它使用的回收算法-“标记-清除”算法会导致收集结束时会有大量空间碎片产生，当然通过参数**-XX:+UseCMSCompactAtFullCollection**可以让jvm在执行完标记清除后再做整理。④执行过程中的不确定性，会存在上一次垃圾回收还没执行完，然后垃圾回收又被触发的情况，特别是在并发标记和并发清理阶段会出现，一边回收，系统一边运行，也许没回收完就再次触发full gc，也就是"concurrent mode failure"，此时会进入stop the world，用serial old垃圾收集器来回收。总结一下CMS的相关参数：

1.  -XX:+UseConcMarkSweepGC：启用cms
2. -XX:ConcGCThreads：并发的GC线程数
3.  -XX:+UseCMSCompactAtFullCollection：FullGC之后做压缩整理（减少碎片）
4. -XX:CMSFullGCsBeforeCompaction：多少次FullGC之后压缩一次，默认是0，代表每次FullGC后都会压缩一 次
5. -XX:CMSInitiatingOccupancyFraction: 当老年代使用达到该比例时会触发FullGC（默认是92，这是百分比）
6. -XX:+UseCMSInitiatingOccupancyOnly：只使用设定的回收阈值(-XX:CMSInitiatingOccupancyFraction设定的值)，如果不指定，JVM仅在第一次使用设定值，后续则会自动调整
7.  -XX:+CMSParallellnitialMarkEnabled：表示在初始标记的时候多线程执行，缩短STW
8. -XX:+CMSParallelRemarkEnabled：在重新标记的时候多线程执行，缩短STW;

CMS收集器引出了三色收集算法，因为在并发标记和并发收集的情况下，对象间的引用可能发生变化，多标和漏标的情况就有可能发生。三色标记指的是把Gcroots可达性分析遍历对象过程中遇到的对象， 按照“是否访问过”这个条件标记成以下三种颜色：

- 黑色：表示对象已经被垃圾收集器访问过， 且这个对象的所有引用都已经扫描过。黑色对象不可能直接（不经过 灰色对象） 指向某个白色对象。
- 灰色：表示对象已经被垃圾收集器访问过， 但这个对象上至少存在一个引用还没有被扫描过。
- 白色：表示对象尚未被垃圾收集器访问过。 显然在可达性分析刚刚开始的阶段， 所有的对象都是白色的， 若在分析结束的阶段， 仍然是白色的对象， 即代表不可达。

多标-浮动垃圾

在并发标记过程中，如果由于方法运行结束导致部分局部变量(gcroot)被销毁，这个gcroot引用的对象之前又被扫描过 (被标记为非垃圾对象)，那么本轮GC不会回收这部分内存。这部分本应该回收但是没有回收到的内存，被称之为“浮动垃圾”。浮动垃圾并不会影响垃圾回收的正确性，只是需要等到下一轮垃圾回收中才被清除。

**针对并发标记(还有并发清理)开始后产生的新对象，通常的做法是直接全部当成黑色**，本轮不会进行清除。这部分对象期间可能也会变为垃圾，这也算是浮动垃圾的一部分。

漏标-读写屏障

漏标会导致被引用的对象被当成垃圾误删除，这是严重bug，必须解决，有两种解决方案： **增量更新**（Incremental Update） 和**原始快照**（SATB） 。

**增量更新**就是当黑色对象插入新的指向白色对象的引用关系时， 就将这个新插入的引用记录下来， 等并发扫描结束之后， 再将这些记录过的引用关系中的黑色对象为根， 重新扫描一次。 这可以简化理解为， **黑色对象一旦新插入了指向白色对象的引用之后， 它就变回灰色对象了。**

**原始快照**就是当灰色对象要删除指向白色对象的引用关系时， 就将这个要删除的引用记录下来， 在并发扫描结束之后， 再将这些记录过的引用关系中的灰色对象为根， 重新扫描一次，这样就能扫描到白色的对象，将白色对象直接标记为黑色(**目的就是让这种对象在本轮gc清理中能存活下来，待下一轮gc的时候重新扫描，这个对象也有可能是浮动垃圾**) 以上无论是对引用关系记录的插入还是删除， 虚拟机的记录操作都是通过**写屏障**实现的。

什么是写屏障？

所谓的写屏障，其实就是指在赋值操作前后，加入一些处理（可以参考AOP的概念）：

当对象B的成员变量的引用发生变化时，比如引用消失（a.b.d = null），我们可以利用写屏障，将B原来成员变量的引用对象D记录下来：

**写屏障实现SATB**

当对象B的成员变量的引用发生变化时，比如引用消失（a.b.d = null），我们可以利用写屏障，将B原来成员变量的引用对象D记录下来：

> void pre_write_barrier(oop* field) { 
>
>  oop old_value = *field; // 获取旧值 
>
> remark_set.add(old_value); // 记录原来的引用对象 4 
>
> }

**写屏障实现增量更新**

当对象A的成员变量的引用发生变化时，比如新增引用（a.d = d），我们可以利用写屏障，将A新的成员变量引用对象D 记录下来：

> void post_write_barrier(oop* field, oop new_value) { 
>
>  remark_set.add(new_value); // 记录新引用的对象 
>
>  }

**读屏障**

读屏障是直接针对第一步：D d = a.b.d，当读取成员变量时，一律记录下来：

> void pre_load_barrier(oop* field) { 
>
>  oop old_value = *field; 
>
>  remark_set.add(old_value); // 记录读取到的对象 
>
> }

现代追踪式（可达性分析）的垃圾回收器几乎都借鉴了三色标记的算法思想，尽管实现的方式不尽相同：比如白色/黑色 集合一般都不会出现（但是有其他体现颜色的地方）、**灰色集合可以通过栈/队列/缓存日志等方式进行实现、遍历方式可以是广度/深度遍历**等等。CMS收集器处理漏标的方案是写屏障+增量更新，G1收集器处理漏标的方案是写屏障+SATB，ZGC采用读屏障。那么**为什么G1用SATB？CMS用增量更新？**借用大佬的想法：SATB相对增量更新效率会高(当然SATB可能造成更多的浮动垃圾)，因为不需要在重新标记阶段再次深度扫描被删除引用对象，而CMS对增量引用的根对象会做深度扫描，G1因为很多对象都位于不同的region，CMS就一块老年代区域，重新深度扫描对象的话G1的代价会比CMS高，所以G1选择SATB不深度扫描对象，只是简单标记，等到下一轮GC 再深度扫描。

在新生代做GCRoots可达性扫描过程中可能会碰到跨代引用的对象，这种如果又去对老年代再去扫描效率太低了。 为此，在新生代可以引入**记录集**的数据结构（记录从非收集区到收集区的指针集合），避免把整个老年代加入GCRoots扫描范围。hotspot使用一种叫做“卡表”的方式实现记忆集，也是目前最常用的一种方式。关于卡表与记忆集的关系， 可以类比为Java语言中HashMap与Map的关系。**卡表是使用一个字节数组实现：CARD_TABLE[ ]，每个元素对应着其标识的内存区域一块特定大小的内存块，称为“卡页”。**hotSpot使用的卡页是2^9大小，即512字节。一个卡页中可包含多个对象，只要有一个对象的字段存在跨代指针，其对应的卡表的元素标识就变成1，表示该元素变脏，否则为0。GC时，只要筛选本收集区的卡表中变脏的元素加入GCRoots里。卡表变脏上面已经说了，但是需要知道如何让卡表变脏，即发生引用字段赋值时，如何更新卡表对应的标识为1。 **Hotspot使用写屏障维护卡表状态**。



总结完，那么亿级电商系统的JVM参数怎么设置呢？对于JDK8默认的垃圾回收器是-XX:+UseParallelGC(年轻代)和-XX:+UseParallelOldGC(老年代)，如果内存较大(超过4个G，只是经验 值)，系统对停顿时间比较敏感，我们可以使用**ParNew+CMS(-XX:+UseParNewGC -XX:+UseConcMarkSweepGC)**。对于多大的对象直接进入老年代**(参数-XX:PretenureSizeThreshold)**，这个一般可以结合你自己系统看下有没有什么大对象生成，预估下大对象的大小，一般来说设置为1M就差不多了，很少有超过1M的大对象，这些对象一般就是你系统初始化分配的缓存对象，比如大的缓存List，Map之类的对象。

>  ‐Xms3072M ‐Xmx3072M ‐Xmn2048M ‐Xss1M ‐XX:MetaspaceSize=256M ‐XX:MaxMetaspaceSize=256M ‐XX:SurvivorRatio=8  ‐XX:MaxTenuringThreshold=5 ‐XX:PretenureSizeThreshold=1M ‐XX:+UseParNewGC ‐XX:+UseConcMarkSweepGC ‐XX:CMSInitiatingOccupancyFraction=92 ‐XX:+UseCMSCompactAtFullCollection ‐XX:CMSFullGCsBeforeCompaction=0

我们JVM优化的主要目的就是**尽可能的让对象都在新生代里分配和回收，尽量别让太对对象频繁进入老年代，避免频繁对老年代进行垃圾回收，同时给系统充足的内存大小，避免新生代频繁的进行垃圾回收。**

#### JAVA线上故障排查

基本问题就是cpu、磁盘、内存、GC问题、网络

##### CPU

cpu异常往往还是比较好定位的。原因包括业务逻辑问题(死循环)、频繁gc以及上下文切换过多。而最常见的往往是业务逻辑(或者框架逻辑)导致的，可以使用jstack来分析对应的堆栈情况。

**使用jstack分析cpu**

1. 我们先用ps命令找到对应进程的pid(如果你有好几个目标进程，可以先用top看一下哪个占用比较高)。接着用top -H -p pid来找到cpu使用率比较高的一些线程。
2. 然后将占用最高的pid转换为16进制printf '%x\n' pid得到nid
3. 接着直接在jstack中找到相应的堆栈信息jstack pid |grep 'nid' -C5 –color，当然更常见的是我们对整个jstack文件进行分析，通常我们会比较关注WAITING和TIMED_WAITING的部分，BLOCKED就不用说了。我们可以使用命令cat jstack.log | grep "java.lang.Thread.State" | sort -nr | uniq -c来对jstack的状态有一个整体的把握

**频繁gc**

使用jstat -gc pid 1000命令来对gc分代变化情况进行观察，1000表示采样间隔(ms)，S0C/S1C、S0U/S1U、EC/EU、OC/OU、MC/MU分别代表两个Survivor区、Eden区、老年代、元数据区的容量和使用量。YGC/YGT、FGC/FGCT、GCT则代表YoungGc、FullGc的耗时和次数以及总耗时。如果看到gc比较频繁，再针对gc方面做进一步分析。

**上下文切换**

针对频繁上下文问题，我们可以使用vmstat命令来进行查看。cs(context switch)一列则代表了上下文切换的次数。

如果我们希望对特定的pid进行监控那么可以使用 pidstat -w pid命令，cswch和nvcswch表示自愿及非自愿切换。

##### 磁盘

首先是磁盘空间方面，我们直接使用df -hl来查看文件系统状态，更多时候，磁盘问题还是性能上的问题。我们可以通过iostatiostat -d -k -x来进行分析。

最后一列%util可以看到每块磁盘写入的程度，而rrqpm/s以及wrqm/s分别表示读写速度，一般就能帮助定位到具体哪块磁盘出现问题了。我们还需要知道是哪个进程在进行读写，可以用iotop命令来进行定位文件读写的来源。不过这边拿到的是tid，我们要转换成pid，可以通过readlink来找到pidreadlink -f /proc/*/task/tid/../..。找到pid之后就可以看这个进程具体的读写情况cat /proc/pid/io。我们还可以通过lsof命令来确定具体的文件读写情况lsof -p pid。

##### 内存

内存问题排查起来相对比CPU麻烦一些，场景也比较多。主要包括OOM、GC问题和堆外内存。一般来讲，我们会先用free命令先来检查一发内存的各种情况。

**堆外内存**

内存问题大多还都是堆内内存问题。表象上主要分为OOM和StackOverflow。

**OOM**

- java.lang.OutOfMemoryError: unable to create new native thread

  这个意思是没有足够的内存空间给线程分配java栈，基本上还是线程池代码写的有问题，比如说忘记shutdown，所以说应该首先从代码层面来寻找问题，使用jstack或者jmap。如果一切都正常，JVM方面可以通过指定Xss(栈内存)来减少单个thread stack的大小。

- java.lang.OutOfMemoryError: Java heap space

  这个意思是堆的内存占用已经达到-Xmx设置的最大值，应该是最常见的OOM错误了。解决思路仍然是先应该在代码中找，怀疑存在内存泄漏，通过jstack和jmap去定位问题。如果说一切都正常，才需要通过调整Xmx的值来扩大内存。

- java.lang.OutOfMemoryError: Meta space

  这个意思是元数据区的内存占用已经达到XX:MaxMetaspaceSize设置的最大值，排查思路和上面的一致，可以调整参数。

**Stack Overflow**

java.lang.StackOverflowError

表示线程栈需要的内存大于Xss值，同样也是先进行排查，参数方面通过Xss来调整，但调整的太大可能又会引起OOM。

**使用JMAP定位代码内存泄漏//TODO**

日常开发中，代码产生内存泄漏是比较常见的事，并且比较隐蔽，需要开发者更加关注细节。比如说每次请求都new对象，导致大量重复创建对象；进行文件流操作但未正确关闭；手动不当触发gc；ByteBuffer缓存分配不合理等都会造成代码OOM。

**gc问题和线程**

gc问题除了影响cpu也会影响内存，排查思路也是一致的。一般先使用jstat来查看分代变化情况，比如youngGC或者fullGC次数是不是太多呀；EU、OU等指标增长是不是异常呀等。

**堆外内存**

首先堆外内存溢出表现就是物理常驻内存增长快，报错的话视使用方式都不确定，如果由于使用Netty导致的，那错误日志里可能会出现OutOfDirectMemoryError错误，如果直接是DirectByteBuffer，那会报OutOfMemoryError: Direct buffer memory。

##### 总结：

线上发生故障的话，可能是cpu、磁盘、内存出现问题。cpu出现问题的话估计是业务逻辑出现死循环、频繁gc或者是线程上下文切换过多。可以使用jstack来分析对应的堆栈情况，可以先用top看一下哪个占用比较高，接着用top -H -p pid来找到cpu使用率比较高的一些线程。然后将占用最高的pid转换为16进制printf '%x\n' pid得到nid，接着直接在jstack中找到相应的堆栈信息jstack pid |grep 'nid' -C5 –color，当然更常见的是我们对整个jstack文件进行分析，通常我们会比较关注WAITING和TIMED_WAITING的部分，BLOCKED就不用说了。我们可以使用命令cat jstack.log | grep "java.lang.Thread.State" | sort -nr | uniq -c来对jstack的状态有一个整体的把握。频繁gc的 话使用jstat -gc pid 1000命令来对gc分代变化情况进行观察 1000（ms）为采样间隔。上下文切换我们可以使用vmstat命令来进行查看。如果我们希望对特定的pid进行监控那么可以使用 pidstat -w pid命令。

磁盘问题的话不是磁盘空间出现问题就是磁盘性能。我们直接使用df -hl来查看文件系统状态，磁盘性能的话，通过iostatiostat -d -k -x来分析。其中三个参数挺重要，%util可以看到每块磁盘写入的程度，而rrqpm/s以及wrqm/s分别表示读写速度，一般就能帮助定位到具体哪块磁盘出现问题了。我们还需要知道是哪个进程在进行读写，可以用iotop命令来进行定位文件读写的来源。不过这边拿到的是tid，我们要转换成pid

内存排查的话比较麻烦，主要包括OOM、GC问题和堆外内存。一般来讲，我们会先用free命令先来检查一发内存的各种情况。

#### 优化if/else

1. 提前return，去除掉不必要的else：如果if-else代码块包含return语句，可以考虑通过提前return，把多余else干掉。
2. 使用三目运算符。
3. 使用枚举的方式优化if-else逻辑分支（表驱动方法）。
4. 合并条件表达式：如果有一系列条件返回一样的结果，可以将它们合并为一个条件表达式，让逻辑更加清晰。
5. 表驱动法（hashmap）
6. 优化逻辑结构，让正常流程走主干：将条件反转使异常情况先退出，让正常流程维持在主干流程，可以让代码结构更加清晰。

#### 接口幂等性的处理方案

幂等性是开发当中很常见也很重要的一个需求，尤其是**支付**、**订单**等与金钱挂钩的服务，保证接口幂等性尤其重要。在实际开发中，我们需要针对不同的业务场景我们需要灵活的选择幂等性的实现方式：

1. 对于下单等存在唯一主键的，可以使用“**唯一主键方案**”的方式实现。
2. 对于更新订单状态等相关的更新场景操作，使用“**乐观锁方案**”实现更为简单。
3. 对于上下游这种，下游请求上游，上游服务可以使用“**下游传递唯一序列号方案**”更为合理。
4. 类似于**前端重复提交**、**重复下单**、**没有唯一ID号**的场景，可以通过 `Token` 与 `Redis` 配合的“**防重 Token 方案**”实现更为快捷。

#### 线上服务平均响应时间太长，怎么排查？

1. 为代码添加上详细的打印日志；**不建议**（重新添加部署代码以及日志会大量占用磁盘空间）
2. 搭建模拟线上服务接口响应时间偏长的环境；SpringBoot 服务接口 + JMeter 模拟服务接口调用；
3. 使用诊断神器 Arthas 提供的命令 **trace** 命令进行响应时间偏长的问题排查；
   1. 首先需要下载阿里开源的Arthas 的诊断工具 Jar 包，下载地址：https://arthas.aliyun.com/arthas-boot.jar ；然后将 Jar 包放到 **部署服务接口项目的服务器中** 。
   2. 然后使用 ps 命令，查询出当前运行服务接口的程序进程号；例如：本文章模拟的服务接口程序 Jar 包名称为 springboot_arthas-1.0.0.jar ，所以命令为：**ps -ef | grep springboot_arthas-1.0.0** 。
   3. 然后运行Arthas 诊断工具，命令：java -jar arthas-boot.jar ，需要手动选择要诊断/监控的java 进程，并且此工具也会列出全部的java进程号，你只需要输入 它们最前的序号 **[1]** 即可
   4. 运行完后，可以使用 **trace命令** 监控服务接口方法中调用的其它方法的耗时；`trace` 命令能主动搜索 `class-pattern`／`method-pattern` 对应的方法调用路径，渲染和统计整个调用链路上的所有性能开销和追踪调用链路。**具体命令格式**：trace 全限定类名。**具体命令**： **trace com.lyl.controller.TestController process**。process：TestController 类中的方法；

#### MySql主从复制的几种方式

- 异步复制
- 多线程复制
- 半同步复制

#### 单点登录的三种实现方式

- 父域 Cookie

  Cookie 的作用域由 domain 属性和 path 属性共同决定。domain 属性的有效值为当前域或其父域的域名/IP地址，在 Tomcat 中，domain 属性默认为当前域的域名/IP地址。path 属性的有效值是以“/”开头的路径，在 Tomcat 中，path 属性默认为当前 Web 应用的上下文路径。如果将 Cookie 的 domain 属性设置为当前域的父域，那么就认为它是父域 Cookie。Cookie 有一个特点，即父域中的 Cookie 被子域所共享，换言之，**子域会自动继承父域中的Cookie**。（实现简单但是不支持跨主域）

- 认证中心

  可以部署一个认证中心，认证中心就是一个专门负责处理登录请求的独立的 Web 服务。

  应用系统检查当前请求有没有 Token，如果没有，说明用户在当前系统中尚未登录，那么就将页面跳转至认证中心。由于这个操作会将认证中心的 Cookie 自动带过去，因此，认证中心能够根据 Cookie 知道用户是否已经登录过了。如果认证中心发现用户尚未登录，则返回登录页面，等待用户登录，如果发现用户已经登录过了，就不会让用户再次登录了，而是会跳转回目标 URL ，并在跳转前生成一个 Token，拼接在目标 URL 的后面，回传给目标应用系统。

  应用系统拿到 Token 之后，还需要向认证中心确认下 Token 的合法性，防止用户伪造。确认无误后，应用系统记录用户的登录状态，并将 Token 写入 Cookie，然后给本次访问放行。（注意这个 Cookie 是当前应用系统的，其他应用系统是访问不到的。）当用户再次访问当前应用系统时，就会自动带上这个 Token，应用系统验证 Token 发现用户已登录，于是就不会有认证中心什么事了。

- LocalStorage跨域

  前端拿到 Session ID （或 Token ）后，除了将它写入自己的 LocalStorage 中之外，还可以通过特殊手段将它写入多个其他域下的 LocalStorage 中。

  此种实现方式完全由前端控制，几乎不需要后端参与，同样支持跨域。

#### 在项目中，如何应对高并发流量

**缓存**，**降级**，**限流**。

**限流**：

限流的常用处理手段有：计数器、滑动窗口、漏桶、令牌。

**计数器**

计数器是一种比较简单的限流算法，用途比较广泛，在接口层面，很多地方使用这种方式限流。在一段时间内，进行计数，与阀值进行比较，到了时间临界点，将计数器清0。

**滑动窗口**

由于计数器存在临界点缺陷，后来出现了滑动窗口算法来解决。

滑动窗口的意思是说把固定时间片，进行划分，并且随着时间的流逝，进行移动，这样就巧妙的避开了计数器的临界点问题。也就是说这些固定数量的可以移动的格子，将会进行计数判断阀值，因此格子的数量影响着滑动窗口算法的精度。

**漏桶**

虽然滑动窗口有效避免了时间临界点的问题，但是依然有时间片的概念，而漏桶算法在这方面比滑动窗口而言，更加先进。

**有一个固定的桶，进水的速率是不确定的，但是出水的速率是恒定的，当水满的时候是会溢出的。**

**令牌桶**

注意到，漏桶的出水速度是恒定的，那么意味着如果瞬时大流量的话，将有大部分请求被丢弃掉（也就是所谓的溢出）。为了解决这个问题，令牌桶进行了算法改进。

生成令牌的速度是恒定的，而请求去拿令牌是没有速度限制的。这意味，面对瞬时大流量，该算法可以在短时间内请求拿到大量令牌，而且拿令牌的过程并不是消耗很大的事情。（有一点生产令牌，消费令牌的意味）

不论是对于令牌桶拿不到令牌被拒绝，还是漏桶的水满了溢出，都是为了保证大部分流量的正常使用，而牺牲掉了少部分流量，这是合理的，如果因为极少部分流量需要保证的话，那么就可能导致系统达到极限而挂掉，得不偿失。

**分布式场景下的限流：Nginx+Lua，Redis+Lua**